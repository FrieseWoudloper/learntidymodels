---
title: "Multinomial modeling with tidymodels"
output: 
  learnr::tutorial:
    progressive: false
    allow_skip: true
    css: css/style.css
runtime: shiny_prerendered
---

<script language="JavaScript" src="js/exercise-font-size.js"></script>

```{r setup, include=FALSE, message=FALSE}
library(learnr)
library(knitr)
library(gradethis)
library(sortable)
# library(GGally)
library(skimr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      exercise.checker = gradethis::grade_learnr,
                      out.width='96%', fig.align='center')

library(tidyverse)
library(tidymodels)
library(palmerpenguins)

peng_colors <- c("darkorange","purple","cyan4")

# set the theme
theme_set(theme_minimal())


# peng <- penguins %>%
#   drop_na()
# 
# splits <- initial_split(penguins, strata = species)
# peng_training <- training(splits)
# peng_test  <- testing(splits)
# 
# peng_rec <- 
#   recipe(species ~ ., data=peng) %>%
#     step_naomit(all_predictors()) %>%
#   step_dummy(all_nominal(), -species)
# 
# peng_prep <- prep(peng_rec)
# juice(peng_prep)
# 
# rf_spec <- rand_forest(trees = 1000, mtry = 3) %>%
#   set_mode("classification") %>%
#   set_engine("ranger", importance = "permutation")
# 
# peng_wf <- workflow() %>%
#   add_recipe(peng_rec) %>%
#   add_model(rf_spec)
# 
# peng_fit <- fit(peng_wf, data = peng_training)
# 
# peng_pred <- predict(peng_fit, peng_test, type = "prob") %>%
#     bind_cols(peng_test %>% select(species))
# 
# peng_pred %>%
#     roc_curve(truth = species, contains(".pred")) %>%
#     autoplot()
# 
# peng_pred %>%
#     roc_auc(truth = species, contains(".pred"))
```


## Welcome

Multinomial (multiclass) classification is the problem of classifying observations into one of three or more classes. 

This tutorial will teach you how to do multinomial classification with random forest models using the [tidymodels](https://www.tidymodels.org) ecosystem, a collection of modeling packages designed with common APIs and a shared philosophy.


### Learning objectives

This tutorial focuses on how to create a multinomial random forest model using  [tidymodels](https://www.tidymodels.org/packages/) packages.    

As such you will learn how to:

+ Use [parsnip](https://parsnip.tidymodels.org/) functions to create a random forest model specification with [ranger](https://www.rdocumentation.org/packages/ranger/versions/0.12.1/topics/ranger) package      
+ Pre-process our data with [recipes](https://recipes.tidymodels.org/)    
+ Combine a model and a recipe with [workflows](https://workflows.tidymodels.org/)
<!-- + Create bootstrap samples with [rsamples](https://rsamples.tidymodels.org/)     -->
<!-- + Apply the model to bootstrap samples using [tune](https://tune.tidymodels.org/) -->

### Pre-requisites

If you are new to [tidymodels](https://www.tidymodels.org), you can learn what you need with the five [Get Started articles on tidymodels.org](https://www.tidymodels.org/start/). 

The second article [Preprocessing your data with recipes](https://www.tidymodels.org/start/recipes/) explains how to use **recipes** and **workflows** packages.    
<!-- + The third article, [Evaluate your model with resampling](https://www.tidymodels.org/start/resampling/), shows how to do apply resampling methods with rsample and tune packages.       -->
<!-- + The fifth article [A predictive modeling case study](https://www.tidymodels.org/start/case-study) shows a whole predictive modeling workflow with random forest, including how to tune model hyperparameters. -->

If you aren't familiar with the tidymodels yet, reading these articles would be helpful before going through this tutorial.  

Let's get started!


## The penguins data

Let's use the [penguins](https://allisonhorst.github.io/palmerpenguins/) data to train a model to predict penguin species based on a set of predictor variables.

The `penguins` data was collected on penguin species nested along the Palmer Archipelago, a group of islands off the northwestern coast of the Antarctic Peninsula. The data set includes nesting location (island), various body part measurements and total body weight on three penguin species: Chinstrap, Gentoo, and Adelie.

```{r peng-int-img, echo=FALSE, fig.cap='Artwork by @allison_horst', echo=FALSE}
include_graphics("https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png")
```


Let's load the necessary libraries and take a look at our data!

To see the first ten rows of the data set click on **Run Code**.   
You can use the arrow that appears at the top right of the table to scroll through all of the columns in `penguins`.

```{r intro-peng, exercise=TRUE, exercise.lines=5}
library(tidymodels)
library(palmerpenguins) # for penguins data

penguins
```

Alternatively, we can use `glimpse` to neatly list the columns.

```{r glmp-peng, exercise=TRUE}
glimpse(___)
```

```{r glmp-peng-solution}
glimpse(penguins)
```

Load the `skimr` library to use the `skim()` function to summarize the variables in the data set.

```{r skim-1, exercise=TRUE}
library(skimr)
skim(___)

```

```{r skim-1-solution}
library(skimr)
skim(penguins)
```

Isn't that fantastic? With just one line we get lots of useful information about our data set! `r emojifont::emoji("sparkles")` Now, pay attention to the results and see if you can answer the questions below:

```{r skim-quiz1, echo=FALSE}
question("Which variable has the most number of missing values?",
         answer("flipper_length_mm"),
         answer("sex", correct = TRUE),
         answer("body_mass_g"),
         answer("bill_depth_mm"),
         incorrect = "Incorrect. While this variable has some missing values, it is not the highest.",
         allow_retry = TRUE
         )

```


```{r skim-quiz2, echo=FALSE}
question("Which variables in the data set are nominal (categorical)? Select all that apply.",
         answer("flipper_length_mm"),
         answer("sex", correct = TRUE),
         answer("body_mass_g"),
         answer("bill_depth_mm"),
         answer("island", correct = TRUE),
         answer("bill_length_mm"),
         answer("species", correct = TRUE),
         incorrect = "Incorrect. Your selection includes numeric variables or missing a nominal variable",
         allow_retry = TRUE
         )
```

We detected some missing values in our data set. Before moving forward, let's drop rows (observations) with `NA`s (missing values).

```{r na-om, exercise=TRUE}
penguins <- na.omit(___)
```

```{r na-om-solution}
penguins <- na.omit(penguins)
```

Let's explore the penguins further and take a look at the distributions of the features (columns of the data frame) across species. 

Let's look at the distribution of nominal features.

Plot the distribution of `species` per `island`:

```{r island-barplot, exercise = TRUE}
# set a color palette to use in all plots!
peng_colors <- c("darkorange","purple","cyan4")

# set the theme
theme_set(theme_minimal())

# plot!
penguins %>%
    ggplot(aes(___, fill = ___)) +
    geom_bar() +
    scale_fill_manual(values=peng_colors)
    
```

```{r island-barplot-solution, exercise = TRUE}
# set a color palette to use in all plots!
peng_colors <- c("darkorange","purple","cyan4")

# set the theme
theme_set(theme_minimal())

# plot!
penguins %>%
    ggplot(aes(island, fill = species)) +
    geom_bar() +
    scale_fill_manual(values=peng_colors)
```


```{r island-quiz, echo=FALSE}
question("According to the plot, select all that are correct.",
         answer("Chinstrap penguins only nest on Torgersen island"),
         answer("Adelie penguins nest on all three islands", correct = TRUE),
         answer("Gentoo penguins only nest on Biscoe island", correct = TRUE),
         answer("Adelie penguins only nest on Dream island"),
         incorrect = "Incorrect. Try again!",
         allow_retry = TRUE
         )

```

Let's look at sex distribution across species.

```{r sex-barplot, exercise = TRUE}
penguins %>%
    ggplot(aes(___, fill = ___)) +
    geom_bar()
```

```{r sex-barplot-solution}
penguins %>%
    ggplot(aes(species, fill = sex)) +
    geom_bar()
```

You can also simply look at the fraction of sex by species:

```{r sex-frac, exercise = TRUE}
penguins %>%
    count(___, ___) %>%
    group_by(___) %>%
    mutate(frac = n/sum(n))
```

```{r sex-frac-solution}
penguins %>%
    count(species, sex) %>%
    group_by(species) %>%
    mutate(frac = n/sum(n))
```

Overall, sex seems to be equally distributed across species.


Let's shift our attention to numeric features. 

```{r num-quiz, echo=FALSE}
question("Select all features that are numeric.",
         answer("flipper_length_mm", correct = TRUE),
         answer("sex"),
         answer("body_mass_g", correct = TRUE),
         answer("bill_depth_mm", correct = TRUE),
         answer("island"),
         answer("bill_length_mm", correct = TRUE),
         answer("species"),
         incorrect = "Incorrect. Your selection includes nominal features or missing a numeric variable",
         allow_retry = TRUE
         )

```

If you're curious, here's the definition of bill dimensions:

![Artwork by @allison_horst](inst/tutorials/multinomial_rf/img/bill_depth.png)


Select the continuous features and plot their distribution by penguin species

```{r hist, exercise = TRUE}
library(tidyr)
penguins %>%
    tidyr::pivot_longer(cols=___, names_to="features") %>% 
    ggplot(aes(value, fill=species)) +
    geom_histogram(bins = 20) +
    facet_grid(species~features, scales="free_x") 
```

```{r hist-solution}
library(tidyr)
penguins %>%
    tidyr::pivot_longer(cols=bill_length_mm:body_mass_g, names_to="features") %>% 
    ggplot(aes(value, fill=species)) +
    geom_histogram(bins = 20) +
    facet_grid(species~features, scales="free_x") 
```

Looks like Gentoo peng


## Build a random forest model

To predict the penguin species based on the measurements in the `penguins` data set, we will build a random forest model. [Random forest](https://en.wikipedia.org/wiki/Random_forest) is an [ensamble learning](https://en.wikipedia.org/wiki/Ensemble_learning) method that can be used for classification or regression problems. It combines  [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) models with [bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating) to avoid overfitting and increase accuracy.

Random forest algorithm works by constructing a large number of [decision trees](https://en.wikipedia.org/wiki/Decision_tree_learning) (typically thousands) during model training. While constructing each tree, only a *random subset* of features (columns of your data frame) are considered for splitting at each node of the decision tree. Furthermore, each decision tree is built with a slightly different version of the training data by creating [bootstrapped samples](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)). This introduces randomness to the model and allows the trees to be different from one another. Finally, once all the trees are trained and a new data set is introduced to the model for prediction, results from all trees are aggregated into one by averaging (for a regression problem) or determining the most frequently predicted class (for a classification problem) across all the trees.




